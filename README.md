# TurtleBot3 Smart Automation System

**Course:** Smart Mobility  
**Target Platform:** Ubuntu 22.04 + ROS2 Humble

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Testing](#testing)
- [Operating System Concepts](#operating-system-concepts)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project presents a comprehensive automation system for TurtleBot3 mobile robots using ROS2 Humble on Ubuntu 22.04. It integrates modern AI tools (YOLOv8, MediaPipe) with robotic automation to demonstrate practical applications of operating system concepts including process management, resource monitoring, file I/O, and inter-process communication.

The system provides five core modules:
1. **Setup Automation** - Automated installation and configuration
2. **Health Monitoring** - Real-time system diagnostics and maintenance
3. **Smart Navigation** - Behavior tree-based autonomous navigation
4. **Vision Processing** - YOLOv8 object detection with tracking
5. **Gesture Control** - MediaPipe hand gesture recognition (Custom Feature)

## âœ¨ Features

### 1. Setup Automation (`automation/setup_manager.py`)

- âœ… Automated ROS2 Humble installation with GPG key verification
- âœ… TurtleBot3 package installation (simulation, navigation, SLAM)
- âœ… Workspace creation and automated building
- âœ… Environment configuration with .bashrc integration
- âœ… Systemd service generation for auto-start
- âœ… Comprehensive verification and health checks
- âœ… Rollback support on installation failure

**Unique Approach:** Unlike template projects, this implementation uses:
- Systemd service creation for production deployment
- Multi-stage verification with detailed reporting
- Configuration validation before installation
- Automated testing post-installation

### 2. Health Monitoring (`automation/health_monitor.py`)

- ğŸ¥ Real-time battery monitoring with multi-level alerts (Good/Low/Critical)
- ğŸ” Comprehensive sensor diagnostics (LiDAR, IMU, Camera, Odometry)
- âš™ï¸ Motor health tracking (temperature, current, RPM)
- ğŸ’» System resource monitoring (CPU, Memory, Disk, Network)
- ğŸ“Š Historical data logging with trend analysis
- ğŸš¨ Automated fault detection and recovery
- ğŸ“„ Health report generation (text + JSON)

**Unique Features:**
- Alert cooldown system to prevent spam
- Automated response to critical conditions
- Performance metrics tracking
- Health score calculation (0-100)

### 3. Smart Navigation (`automation/smart_navigator.py`)

- ğŸ—ºï¸ SLAM mapping using Cartographer
- ğŸ§­ Autonomous navigation with Nav2 stack
- ğŸŒ³ Behavior tree-based decision making
- ğŸ“ Multi-waypoint navigation
- ğŸ”„ Patrol route execution
- ğŸ  Return-to-base capability
- ğŸš§ Dynamic obstacle avoidance
- ğŸ“Š Navigation history logging

**Unique Approach:**
- Behavior tree architecture for intelligent decision-making
- Pre-flight checks (battery, obstacles) before navigation
- Waypoint sequencing with progress tracking
- Comprehensive navigation state machine

### 4. Vision Processing (`automation/vision_processor.py`)

- ğŸ‘ï¸ Real-time YOLOv8 object detection
- ğŸ¯ Multi-object tracking support
- ğŸ¤ Object interaction behaviors:
  - Follow object (maintain distance)
  - Avoid objects (collision avoidance)
  - Approach object (go to target)
- ğŸ“¸ Webcam and image file processing
- ğŸ“Š Detection statistics and analytics
- ğŸ”„ ROS2 topic publishing

**Unique Features:**
- Object interaction mode system
- Detection history with class distribution
- Confidence-based filtering
- Real-time performance metrics

### 5. Gesture Control (`automation/gesture_controller.py`) **[Custom Feature]**

- ğŸ–ï¸ Real-time hand gesture recognition using MediaPipe
- ğŸ® Intuitive robot control:
  - Open Palm â†’ STOP
  - Fist â†’ MOVE FORWARD
  - Peace Sign (2 fingers) â†’ TURN LEFT
  - Three Fingers â†’ TURN RIGHT
  - Four Fingers â†’ MOVE BACKWARD
  - Thumbs Up â†’ INCREASE SPEED
  - Thumbs Down â†’ DECREASE SPEED
- ğŸ“¹ Visual feedback with hand landmark overlay
- âš¡ Dynamic speed control
- ğŸ“Š Gesture usage statistics

**Why This Feature:**
- Provides hands-free robot control
- Demonstrates computer vision integration
- Intuitive and accessible interface
- Real-world application potential

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Main Orchestrator                       â”‚
â”‚                      (main.py)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â”€â–º Setup Manager â”€â”€â”€â”€â”€â”€â”€â–º System Installation
            â”‚                           â”œâ”€ ROS2 Humble
            â”‚                           â”œâ”€ TurtleBot3 Packages
            â”‚                           â””â”€ Workspace Build
            â”‚
            â”œâ”€â”€â”€â–º Health Monitor â”€â”€â”€â”€â”€â”€â”€â–º Real-time Diagnostics
            â”‚                           â”œâ”€ Battery Monitoring
            â”‚                           â”œâ”€ Sensor Health
            â”‚                           â”œâ”€ Motor Status
            â”‚                           â””â”€ Resource Tracking
            â”‚
            â”œâ”€â”€â”€â–º Smart Navigator â”€â”€â”€â”€â”€â”€â–º Autonomous Navigation
            â”‚                           â”œâ”€ SLAM Mapping
            â”‚                           â”œâ”€ Path Planning
            â”‚                           â”œâ”€ Behavior Trees
            â”‚                           â””â”€ Waypoint Navigation
            â”‚
            â”œâ”€â”€â”€â–º Vision Processor â”€â”€â”€â”€â”€â–º Object Detection
            â”‚                           â”œâ”€ YOLOv8 Detection
            â”‚                           â”œâ”€ Object Tracking
            â”‚                           â””â”€ Interaction Modes
            â”‚
            â””â”€â”€â”€â–º Gesture Controller â”€â”€â”€â–º Hand Gesture Control
                                        â”œâ”€ MediaPipe Detection
                                        â”œâ”€ Gesture Recognition
                                        â””â”€ Velocity Commands
```

## ğŸ“¦ Prerequisites

### Hardware
- **Computer:** x86_64 system with Ubuntu 22.04 LTS
- **RAM:** Minimum 8GB (16GB recommended)
- **Disk:** 15GB free space
- **Camera:** (Optional) For gesture control and vision features
- **TurtleBot3:** (Optional) Physical robot or use Gazebo simulation

### Software
- **OS:** Ubuntu 22.04 LTS (Jammy Jellyfish)
- **ROS2:** Humble Hawksbill
- **Python:** 3.10+
- **Git:** For repository cloning

## ğŸš€ Installation

### Option 1: Automated Installation (Recommended)

```bash
# Clone the repository
cd ~/Projects/inha-operating-systems/tb3-smart-automation

# Run installation script
sudo ./scripts/install.sh
```

The installation script will:
1. Check system requirements
2. Install ROS2 Humble
3. Install TurtleBot3 packages
4. Create and build workspace
5. Configure environment
6. Install Python dependencies
7. Verify installation

### Option 2: Manual Installation

See [docs/INSTALLATION_GUIDE.md](docs/INSTALLATION_GUIDE.md) for detailed manual installation steps.

### Option 3: Using Python Setup Module

```bash
# Use the setup automation module
python3 main.py setup
```

## ğŸ’» Usage

### Interactive Menu

```bash
python3 main.py --interactive
```

### Command Line Interface

```bash
# Check environment
python3 main.py --check-env

# Setup (first time)
python3 main.py setup

# Health monitoring
python3 main.py health                    # Single check
python3 main.py health --monitor          # Continuous monitoring
python3 main.py health --save-report      # Save report to file

# Navigation
python3 main.py navigate --slam                    # Start SLAM mapping
python3 main.py navigate --save-map my_map         # Save map
python3 main.py navigate --load-map maps/my_map    # Load map
python3 main.py navigate --goto 1.0 1.0 0.0       # Navigate to pose
python3 main.py navigate --patrol                  # Patrol mode
python3 main.py navigate --return-home             # Return to base

# Vision processing
python3 main.py vision --webcam                    # Webcam detection
python3 main.py vision --image path/to/image.jpg   # Detect in image
python3 main.py vision --follow person             # Follow person
python3 main.py vision --duration 60               # Run for 60 seconds

# Gesture control
python3 main.py gesture                            # Start gesture control
python3 main.py gesture --calibrate                # Calibrate gestures
python3 main.py gesture --report                   # Show usage report
```

### Quick Test Scripts

```bash
# Test health monitoring
./scripts/health_check.sh

# Test navigation in simulation
./scripts/test_navigation.sh

# Test vision processing
./scripts/test_vision.sh

# Test gesture control
./scripts/test_gesture.sh
```

## ğŸ“ Project Structure

```
tb3-smart-automation/
â”œâ”€â”€ main.py                          # Main orchestration script
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # This file
â”‚
â”œâ”€â”€ core/                            # Core utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                    # Enhanced logging system
â”‚   â”œâ”€â”€ config_manager.py            # Configuration management
â”‚   â””â”€â”€ utils.py                     # Utility functions
â”‚
â”œâ”€â”€ automation/                      # Automation modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ setup_manager.py             # Setup automation
â”‚   â”œâ”€â”€ health_monitor.py            # Health monitoring
â”‚   â”œâ”€â”€ smart_navigator.py           # Navigation automation
â”‚   â”œâ”€â”€ vision_processor.py          # Vision processing
â”‚   â””â”€â”€ gesture_controller.py        # Gesture control
â”‚
â”œâ”€â”€ config/                          # Configuration files
â”‚   â””â”€â”€ system_config.yaml           # Main configuration
â”‚
â”œâ”€â”€ scripts/                         # Shell scripts
â”‚   â”œâ”€â”€ install.sh                   # Installation script
â”‚   â”œâ”€â”€ health_check.sh              # Health check script
â”‚   â”œâ”€â”€ test_navigation.sh           # Navigation test
â”‚   â”œâ”€â”€ test_vision.sh               # Vision test
â”‚   â””â”€â”€ test_gesture.sh              # Gesture test
â”‚
â”œâ”€â”€ logs/                            # Log files (auto-generated)
â”‚   â”œâ”€â”€ *.log                        # Text logs
â”‚   â””â”€â”€ *.json                       # JSON logs
â”‚
â””â”€â”€ docs/                            # Documentation
    â”œâ”€â”€ INSTALLATION_GUIDE.md        # Detailed installation
    â”œâ”€â”€ TESTING_GUIDE.md             # Testing procedures
    â”œâ”€â”€ API_REFERENCE.md             # API documentation
    â””â”€â”€ TROUBLESHOOTING.md           # Common issues
```

## ğŸ§ª Testing

### Testing on Ubuntu 22.04

1. **Prerequisites Check:**
```bash
python3 main.py --check-env
```

2. **Setup Testing:**
```bash
# Check requirements only (no installation)
python3 main.py setup --check-only

# Full setup
python3 main.py setup
```

3. **Module Testing:**
```bash
# Test each module individually
./scripts/health_check.sh
./scripts/test_vision.sh
./scripts/test_gesture.sh
```

4. **Simulation Testing:**
```bash
# Launch Gazebo simulation
ros2 launch turtlebot3_gazebo empty_world.launch.py

# In another terminal, test navigation
python3 main.py navigate --slam
```

### Without Robot Hardware

All features can be tested in simulation:
- Navigation: Gazebo simulation
- Vision: Webcam or image files
- Gesture: Webcam
- Health: Simulated sensors

See [docs/TESTING_GUIDE.md](docs/TESTING_GUIDE.md) for detailed testing procedures.

## ğŸ–¥ï¸ Operating System Concepts

This project demonstrates key OS concepts:

### 1. Process Management
- **Multi-threading:** Health monitoring and gesture control run in separate threads
- **Process synchronization:** Thread-safe operations with locks
- **Signal handling:** Graceful shutdown on SIGINT/SIGTERM

### 2. Inter-Process Communication
- **ROS2 Topics:** Publisher-subscriber pattern for sensor data
- **ROS2 Services:** Request-response for commands
- **ROS2 Actions:** Long-running tasks with feedback

### 3. Resource Management
- **CPU Monitoring:** Real-time CPU usage tracking
- **Memory Management:** Memory usage and leak detection
- **Disk I/O:** Log file rotation and management

### 4. File Systems
- **Configuration files:** YAML parsing and management
- **Log files:** Structured logging with rotation
- **File I/O:** Reading sensors, writing reports

### 5. System Calls
- **Process execution:** subprocess for shell commands
- **System information:** psutil for hardware metrics
- **Network I/O:** ROS2 network communication

## ğŸ”§ Troubleshooting

### Common Issues

1. **ROS2 not found:**
```bash
source ~/.bashrc
# or
source /opt/ros/humble/setup.bash
```

2. **Permission denied on scripts:**
```bash
chmod +x scripts/*.sh
chmod +x main.py
```

3. **Python module not found:**
```bash
pip3 install -r requirements.txt
```

4. **Gazebo won't start:**
```bash
export TURTLEBOT3_MODEL=burger
killall gzserver gzclient
ros2 launch turtlebot3_gazebo empty_world.launch.py
```

5. **Camera not detected:**
```bash
# Check available cameras
ls /dev/video*

# Try different camera ID in config
gesture.camera_id: 0  # Change to 1, 2, etc.
```

For more issues, see [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md).

## ğŸ“ Configuration

Edit `config/system_config.yaml` to customize:

```yaml
robot:
  model: "burger"      # burger, waffle, waffle_pi
  use_sim: false       # true for simulation

health_monitor:
  check_interval: 5.0  # seconds between checks
  battery_low_threshold: 20.0  # percent

navigation:
  max_linear_speed: 0.22  # m/s
  max_angular_speed: 2.84  # rad/s

vision:
  confidence_threshold: 0.5  # YOLO confidence
  enable_tracking: true

gesture:
  camera_id: 0
  min_detection_confidence: 0.7
```

## ğŸ¤ Contributing

This is an academic project, but suggestions are welcome:

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License

This project is created for educational purposes as part of a Smart Mobility course.

## ğŸ™ Acknowledgments

- ROBOTIS for TurtleBot3 platform and documentation
- ROS2 community for excellent documentation and support
- Ultralytics for YOLOv8
- Google MediaPipe team
- All open-source contributors

## ğŸ“š References

1. ROS2 Humble Documentation: https://docs.ros.org/en/humble/
2. TurtleBot3 Manual: https://emanual.robotis.com/docs/en/platform/turtlebot3/
3. YOLOv8 Documentation: https://docs.ultralytics.com/
4. MediaPipe Documentation: https://developers.google.com/mediapipe
5. Robotics and Autonomous Systems References

---

**Course:** Smart Mobility
